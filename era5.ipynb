{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google up: \"Reanalysis Calibration\"\n",
    " See paper Calibration of Reanalysis Data against Wind Measurements for Energy Production Estimation of Building Integrated Savonius-Type Wind Turbine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.distance import great_circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather stations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yMax, xMin = 54.644172, 77.134437\n",
    "yMin, xMax = 50.354805, 88.087806\n",
    "start = '2018-01-01'\n",
    "end = '2021-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = pd.read_csv('data/weatherstation_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_selected = station_list[(station_list['Широта'] >= yMin) & (station_list['Широта'] <= yMax) & (station_list['Долгота'] >= xMin) & (station_list['Долгота'] <= xMax)]\n",
    "\n",
    "selected_stations_data = pd.read_csv('data/Altai_station_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up earth engine API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=f2EkYHcJLa23nXjQoZF8DdmMEzYSaOu19xn93gkJtbU&tc=mz1tD3_m4AeLfDwbtsIWWwHz6c4pad-cF4YCjujmPPo&cc=WKauaBi6Uib3AFjLYGTrXdQBME99xCBviQ7JF8Hsnsg>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=f2EkYHcJLa23nXjQoZF8DdmMEzYSaOu19xn93gkJtbU&tc=mz1tD3_m4AeLfDwbtsIWWwHz6c4pad-cF4YCjujmPPo&cc=WKauaBi6Uib3AFjLYGTrXdQBME99xCBviQ7JF8Hsnsg</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()\n",
    "\n",
    "# Initialize the library.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset selection, time period, bands, geometry \n",
    "[Link to the dataset](https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_LAND_HOURLY?hl=en#bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_collection = \"ECMWF/ERA5/DAILY\"\n",
    "\n",
    "bands = ['mean_2m_air_temperature', 'minimum_2m_air_temperature', 'maximum_2m_air_temperature', 'total_precipitation', 'u_component_of_wind_10m', 'v_component_of_wind_10m', 'surface_pressure']\n",
    "bands_len = len(bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time selected\n",
      "2018-01-01 00:00:00  --  2021-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.datetime(year=int(start.split('-')[0]), month=int(start.split('-')[1]), day=int(start.split('-')[2]))\n",
    "end_date = datetime.datetime(year=int(end.split('-')[0]), month=int(end.split('-')[1]), day=int(end.split('-')[2]))\n",
    "print(\"Time selected\")\n",
    "print(start_date, \" -- \", end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restricting geometry\n",
    "rectangleBounds = ee.Geometry.Rectangle(\n",
    "  [xMin, yMin, xMax, yMax]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Casting to numpy array, dumping into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:01<00:00, 17.30s/it]\n"
     ]
    }
   ],
   "source": [
    "bands_dict = {}\n",
    "for j in tqdm(range(len(bands))):\n",
    "    #reading dataset band\n",
    "    dataset = ee.ImageCollection(img_collection).filterBounds(rectangleBounds).filter(ee.Filter.date(start_date, end_date)).select(bands[j])\n",
    "    # #resampling to get higher resolution\n",
    "    band2 = dataset.toBands()#.select(bands[j])\n",
    "    proj = band2.projection().getInfo()\n",
    "    crs = proj['crs']\n",
    "    crsTransform = proj['transform']\n",
    "    tmp = dataset.getRegion(geometry=rectangleBounds, crsTransform=crsTransform).getInfo()\n",
    "    tmpdf = pd.DataFrame(tmp[1:], columns = tmp[0])\n",
    "    try:\n",
    "        bands_df[bands[j]] = tmpdf[bands[j]]\n",
    "    except NameError:\n",
    "        bands_df = tmpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display elevation in the region selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/11d2ab843072a34484837e28e14a8434-bf354aa324aeb476213ed5e222dd4012:getPixels\n",
      "\n",
      "Please wait while the thumbnail loads, it may take a moment...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/11d2ab843072a34484837e28e14a8434-bf354aa324aeb476213ed5e222dd4012:getPixels\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Declare elevation dataset\n",
    "elevation = ee.Image(\"CGIAR/SRTM90_V4\")\n",
    "lst_img = elevation.select('elevation')\n",
    "# Restricting geometry\n",
    "widerRectangleBounds = ee.Geometry.Rectangle(\n",
    "  [xMin, yMin , xMax , yMax ]\n",
    ")\n",
    "# Visualisation details\n",
    "url = lst_img.getThumbUrl({\n",
    "    'min': -20, 'max': 2106, 'dimensions': 512, 'region': widerRectangleBounds,\n",
    "    'palette': ['#386641',\n",
    "            '#6a994e',\n",
    "            '#a7c957',\n",
    "            '#fdf7d6',\n",
    "            '#ffffff']})\n",
    "print(url)\n",
    "\n",
    "# Display the thumbnail land elevation.\n",
    "print('\\nPlease wait while the thumbnail loads, it may take a moment...')\n",
    "Image(url=url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binding pixels to stations example\n",
    "\n",
    "The reason to do such a thing is to construct training dataset.\n",
    "Such pairs -- (reanalysis pixel, weather station) -- will allow to train a model that will translate data from reanalysis model to real measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding closes pixel to the stations selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "st_pixel_dict = {}\n",
    "for i in range(len(stations_selected)):\n",
    "    st_coords = stations_selected[['Долгота', 'Широта']].iloc[i].values\n",
    "\n",
    "    tmp_df = bands_df[['longitude', 'latitude']].drop_duplicates()\n",
    "    idx = bands_df[['longitude', 'latitude']].drop_duplicates().apply(\n",
    "        lambda x: great_circle(\n",
    "            (x['longitude'], x['latitude']),\n",
    "            (st_coords[0], st_coords[1])\n",
    "        ).km,\n",
    "        axis=1)\n",
    "    tmp_df['dist'] = idx\n",
    "\n",
    "    tmp_df.nsmallest(1, columns=['dist'])\n",
    "\n",
    "    st_pixel_dict[stations_selected['Наименование станции'].iloc[i]] = tmp_df.nsmallest(1, columns=['dist'])[['longitude', 'latitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting reanalysis data corresponding to pixels that contain a station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21187/4287271505.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_era['id'] = pd.to_datetime(station_era['id'], format=\"%Y/%m/%d\").values\n",
      "/tmp/ipykernel_21187/4287271505.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_era['id'] = pd.to_datetime(station_era['id'], format=\"%Y/%m/%d\").values\n",
      "/tmp/ipykernel_21187/4287271505.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_era['id'] = pd.to_datetime(station_era['id'], format=\"%Y/%m/%d\").values\n",
      "/tmp/ipykernel_21187/4287271505.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_era['id'] = pd.to_datetime(station_era['id'], format=\"%Y/%m/%d\").values\n",
      "/tmp/ipykernel_21187/4287271505.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_era['id'] = pd.to_datetime(station_era['id'], format=\"%Y/%m/%d\").values\n",
      "/tmp/ipykernel_21187/4287271505.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_era['id'] = pd.to_datetime(station_era['id'], format=\"%Y/%m/%d\").values\n",
      "/tmp/ipykernel_21187/4287271505.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_era['id'] = pd.to_datetime(station_era['id'], format=\"%Y/%m/%d\").values\n",
      "/tmp/ipykernel_21187/4287271505.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_era['id'] = pd.to_datetime(station_era['id'], format=\"%Y/%m/%d\").values\n",
      "/tmp/ipykernel_21187/4287271505.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_era['id'] = pd.to_datetime(station_era['id'], format=\"%Y/%m/%d\").values\n",
      "/tmp/ipykernel_21187/4287271505.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_era['id'] = pd.to_datetime(station_era['id'], format=\"%Y/%m/%d\").values\n",
      "/tmp/ipykernel_21187/4287271505.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  station_era['id'] = pd.to_datetime(station_era['id'], format=\"%Y/%m/%d\").values\n"
     ]
    }
   ],
   "source": [
    "k_ = list(st_pixel_dict.keys())[0]\n",
    "dataset_stations = {}\n",
    "vicinity_degree = 1.0 #neighboring pixels to collect for a station\n",
    "X_data = {}\n",
    "for k_ in st_pixel_dict.keys():\n",
    "    curr_pix = st_pixel_dict[k_]\n",
    "    curr_pix_lon = curr_pix['longitude'].values[0]\n",
    "    curr_pix_lat = curr_pix['latitude'].values[0]\n",
    "    #collecting neghboring pixels\n",
    "    station_era = bands_df[(bands_df['longitude'] <= curr_pix_lon + vicinity_degree) \n",
    "            & (bands_df['latitude'] <= curr_pix_lat + vicinity_degree) \n",
    "            & (bands_df['longitude'] >= curr_pix_lon - vicinity_degree) \n",
    "            & (bands_df['latitude'] >= curr_pix_lat - vicinity_degree)]    \n",
    "    station_era['id'] = pd.to_datetime(station_era['id'], format=\"%Y/%m/%d\").values\n",
    "\n",
    "    \n",
    "    dataset_stations[k_] = station_era.drop(columns='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap up together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k_ in dataset_stations.keys():\n",
    "    curr_station_data = selected_stations_data[selected_stations_data['Название метеостанции'] == k_]\n",
    "    curr_station_avg_ws = curr_station_data[['Дата', 'Средняя скорость ветра']].rename(columns={'Дата': 'id'})\n",
    "    curr_station_avg_ws.loc[:, 'id'] = curr_station_avg_ws['id'].astype('str')\n",
    "    dataset_stations[k_].loc[:, 'id'] = dataset_stations[k_]['id'].astype('str')\n",
    "    start_era_date = dataset_stations[k_].min()\n",
    "    last_era_date = dataset_stations[k_].max()\n",
    "    station_data = curr_station_avg_ws[(curr_station_avg_ws.id <= last_era_date.values[0]) & (curr_station_avg_ws.id >= start_era_date.values[0])]\n",
    "    \n",
    "    dataset_stations[k_] = [dataset_stations[k_], station_data.groupby('id').max()]\n",
    "# Xy_station = pd.merge(curr_station_avg_ws, dataset_stations[k_], how='inner', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_len_dict = {}\n",
    "max_lon = 0\n",
    "max_lat = 0\n",
    "for k_ in dataset_stations.keys():\n",
    "    lon_len = len(dataset_stations[k_][0].longitude.unique())\n",
    "    lat_len = len(dataset_stations[k_][0].latitude.unique())\n",
    "    if max_lon <= lon_len:\n",
    "        max_lon = lon_len\n",
    "    if max_lat <= lat_len:\n",
    "        max_lat = lat_len\n",
    "    lon_len_dict[k_] = (lon_len, lat_len)\n",
    "for k_ in dataset_stations.keys():\n",
    "    if lon_len_dict[k_][0] != max_lon or lon_len_dict[k_][1] != max_lat:\n",
    "        del lon_len_dict[k_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join('data', 'nn_data')):\n",
    "    os.makedirs(os.path.join('data', 'nn_data'))\n",
    "for k_ in lon_len_dict.keys():\n",
    "    if not os.path.exists(os.path.join('data', 'nn_data', k_)):\n",
    "        os.makedirs(os.path.join('data', 'nn_data', k_))\n",
    "    #with open(os.path.join('data', 'nn_data', k_)) as \n",
    "    dataset_stations[k_][0].to_csv(os.path.join('data', 'nn_data', k_, 'objects.csv'))\n",
    "    dataset_stations[k_][1].to_csv(os.path.join('data', 'nn_data', k_, 'targets.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "* In this simple example we have downloaded reanalysis data from Google Earth Engine. We also bound this data to weather stations measurements on a pixel basis with its vicinity.\n",
    "\n",
    "* The next steps will be \n",
    "> a. Prepare this data to insert into ML/DL pipeline for training.\n",
    "\n",
    "> b. Develop a ML/DL model that will train on this data and learn how to translate reanalysis data to the real measurements from weather stations.\n",
    "\n",
    "* See `train_model.ipynb`\n",
    "\n",
    "* After the model is trained, one can obtain refined model at any pixel of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c403dcaf6f0351a93b8b6ceb8c1c4fdaf5a1bb6b53e15407b0dfe79f28297d74"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ee')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
